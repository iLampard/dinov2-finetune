# Finetuning DINOv2 with PEFT for Downstream Tasks

This project demonstrates how to finetune Meta's DINOv2 model on various downstream tasks, utilizing visual datasets such as VTAB (Visual Task Adaptation Benchmark). We explore the use of Low-Rank Adaptation (LoRA) to efficiently adapt the DINOv2 encoder for different vision tasks.


## About This Project

This repository is an extension and adaptation of the work. It builds upon the original implementation to showcase finetuning DINOv2 on a broader range of downstream tasks, with a focus on datasets from the Visual Task Adaptation Benchmark (VTAB).

## Getting Started

### Prerequisites


## References

- [RobvanGastel/dinov2-finetune](https://github.com/RobvanGastel/dinov2-finetune)
- [Meta AI/DINOv2](https://github.com/facebookresearch/dinov2)
- [Visual Task Adaptation Benchmark](https://github.com/google-research/vision_benchmark)
- [zjysteven/lmms-finetune](https://github.com/zjysteven/lmms-finetune/blob/main/train.py)
- [NielsRogge/Transformers-Tutorials/DINOv2](https://github.com/NielsRogge/Transformers-Tutorials/blob/master/DINOv2/Fine_tune_DINOv2_for_image_classification_%5Bminimal%5D.ipynb)
